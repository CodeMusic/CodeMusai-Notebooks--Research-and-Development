{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "214a1658-f0b0-44f0-895f-7e6e36a42119",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CodeMusai Alpha - 0.0.2\n",
    "\n",
    "#Create a concept, memoryspan/blockSize that defines awareness context when making a prediction.\n",
    "#The last model was always 2 due to the data-structure, this enhncement will add meta-parameters.\n",
    "\n",
    "#These results will be a lot better then the last, but due to model simplicity lowish quality \n",
    "#results are still expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d98e51fe-6900-4c15-871e-f3883349f8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'painted', 'christmas', 'an', 'original', 'story', 'of', 'life']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt #diagrams\n",
    "%matplotlib inline\n",
    "\n",
    "words = open('activeTrainingMaterial_lower.txt', 'r').read().lower().split()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f930fd64-3e0f-4463-a7d1-d022da003de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156969"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1e8d8d2a-f792-48c6-890d-232ea522c8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "30 chars found\n",
      "{1: '.', 2: ';', 3: '?', 4: 'a', 5: 'b', 6: 'c', 7: 'd', 8: 'e', 9: 'f', 10: 'g', 11: 'h', 12: 'i', 13: 'j', 14: 'k', 15: 'l', 16: 'm', 17: 'n', 18: 'o', 19: 'p', 20: 'q', 21: 'r', 22: 's', 23: 't', 24: 'u', 25: 'v', 26: 'w', 27: 'x', 28: 'y', 29: 'z'}\n"
     ]
    }
   ],
   "source": [
    "#config for later\n",
    "block_size = 3 #context for prediction\n",
    "numNeurons = 10\n",
    "nembd = 16\n",
    "batch_size = 32\n",
    "\n",
    "def configure(theBlockSize, theNumNeurons, theNembd, theBatchSize):#32,16,10,3\n",
    "    global block_size, numNeurons, nembd, batch_size\n",
    "    block_size = theBlockSize\n",
    "    numNeurons = theNumNeurons\n",
    "    nembd = theNembd\n",
    "    batch_size = theBatchSize \n",
    "\n",
    "#build vocabulary\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "print(chars)\n",
    "characterCount = len(chars)+1\n",
    "print(f\"{characterCount} chars found\")\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "#spotIdx = stoi['.']\n",
    "#spotEndIdx = stoi['\\'']\n",
    "#stoi['.'] = 0\n",
    "#stoi['\\''] = spotIdx\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(itos)\n",
    "ix = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9fd40e5e-ab32-4f75-8cae-cb28a9d6e7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the Dataset...\n",
      "torch.Size([774053, 3]) torch.Size([774053])\n",
      "Building the Dataset...\n",
      "torch.Size([95662, 3]) torch.Size([95662])\n",
      "Building the Dataset...\n",
      "torch.Size([96416, 3]) torch.Size([96416])\n"
     ]
    }
   ],
   "source": [
    "#build the dataset\n",
    "def buildDataset(words):    \n",
    "    print('Building the Dataset...');\n",
    "    #block_size = ...\n",
    "    X, Y = [], []\n",
    "    for w in words:\n",
    "        #print(w)\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            #print(''.join(itos[i] for i in context), '---->', itos[ix])\n",
    "            context = context[1:] + [ix] #crop and append\n",
    "            \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(327)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr, Ytr = buildDataset(words[:n1])\n",
    "Xdev, Ydev = buildDataset(words[n1:n2])\n",
    "Xte, Yte = buildDataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5666b5b2-d422-479c-9621-6478f8c61517",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate       (defined for later)\n",
    "def generate(numSamples):\n",
    "    print(f\"Generating {numSamples}...\")\n",
    "    for _ in range(numSamples):\n",
    "        out = []\n",
    "        context = [0] * block_size\n",
    "        while True:\n",
    "            emb = C[torch.tensor([context])] #(1,block_size,d)\n",
    "            h = torch.tanh(emb.view(1, -1) @ W1 + b1)\n",
    "            logits = h @ W2 + b2\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            ix = torch.multinomial(probs, num_samples=1, replacement=True).item() #, replacement=True)\n",
    "            context = context[1:] + [ix]\n",
    "            out.append(ix)\n",
    "    \n",
    "            #print(itos[ix], end='', flush=True)\n",
    "            decodedChar = itos[ix]\n",
    "            if (decodedChar == '.'):\n",
    "                decodedChar = ' '\n",
    "                \n",
    "            print(decodedChar, end='', flush=True)\n",
    "            \n",
    "            if ix == 0:\n",
    "                break\n",
    "                \n",
    "    print('.', end='', flush=True)#print(''.join(out) + '.')   \n",
    "        #output = ''.join(itos[i] for i in out).replace('.', ' ')\n",
    "        #print(output, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7931e20c-4665-412f-96b7-2657bc5b738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def initializeWeights():\n",
    "    print('Initializing Weights...')\n",
    "    #initialize weights, and prepare for training\n",
    "    #~\n",
    "    \n",
    "    #numNeurons = ...\n",
    "    #nembd = ...\n",
    "    #-\n",
    "    #emb = C[Xtr[ix]]  # Should be [32, 3, 2] # Check if elements align before reshaping\n",
    "    #total_elements = emb.numel()  # Should be 32 * 3 * 2 = 192\n",
    "    #new_shape = (-1, 3 * nembd)  # Should lead to (-1, 6) ensuring 192 elements fit\n",
    "    #-\n",
    "    C = torch.randn((characterCount+1, nembd))\n",
    "    \n",
    "    W1 = torch.randn((3*nembd,numNeurons), requires_grad=True)\n",
    "    b1 = torch.randn(numNeurons, requires_grad=True)\n",
    "    \n",
    "    W2 = torch.randn((numNeurons, characterCount), requires_grad=True)\n",
    "    b2 = torch.randn(characterCount, requires_grad=True)\n",
    "    \n",
    "    parameters = [C, W1, b1, W2, b2]\n",
    "    \n",
    "    for p in parameters:\n",
    "        p.requires_grad = True\n",
    "    \n",
    "    lre = torch.linspace(-3, 0, 1000) #0.001 -> -3,    1 -> 0\n",
    "    lrs = 10**lre\n",
    "    \n",
    "    \n",
    "    numParams = sum(p.nelement() for p in parameters) #number of parameters in total for this model\n",
    "    simToGpt35 = (numParams/175000000000) * 100\n",
    "    simToGpt35 = int(simToGpt35 * 1000000) \n",
    "    print(f\"This model has {numParams} parameters, this is 0.00000{simToGpt35}% of gpt3.5\")\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d2e4b718-2318-43f5-a384-d938f75942f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingLoop(trainingIterations, lr, autoPlot):\n",
    "    print(f\"Starting Training of {trainingIterations} at a learning rate of {lr}...\")\n",
    "    lri = []\n",
    "    lossi = []\n",
    "    stepi = []\n",
    "    #autoPlot = False\n",
    "    #batch_size = ...\n",
    "    for i in range(trainingIterations):\n",
    "    \n",
    "        if autoPlot:\n",
    "            if (i > 0 and batch_size % i == 0):\n",
    "                plt.figure(figsize=(8,8))\n",
    "                plt.scatter(C[:, 0].data, C[:,1].data, s=200)\n",
    "                for i in range(C.shape[0]):\n",
    "                    plt.text(C[i,0].item(), C[i,1].item(), itos[i], ha=\"center\", va=\"center\", color='white')\n",
    "                plt.grid('minor')\n",
    "    \n",
    "        #minibatch construct\n",
    "        ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "        #print(C[Xtr[ix]])\n",
    "\n",
    "        \n",
    "        #forward pass\n",
    "        emb = C[Xtr[ix]] #[32, 3, 2)\n",
    "        \n",
    "        h = torch.tanh(emb.view(-1, block_size*nembd) @ W1 + b1) # (32, 100)\n",
    "        logits = h @ W2 + b2 # (32, characterCount)\n",
    "        #print(f\"Logits shape: {logits.shape}\")\n",
    "        #print(f\"Target shape: {Ytr[ix].shape}\") \n",
    "        loss = F.cross_entropy(logits, Ytr[ix]) #IT MUST USE CROSS_ENTROPY\n",
    "        #print(loss.item())\n",
    "        \n",
    "        \n",
    "        \n",
    "        #backward pass\n",
    "        for p in parameters:\n",
    "            if not p.requires_grad:\n",
    "                print(f\"Parameter {p} does not require gradients.\")\n",
    "            p.grad = None\n",
    "        loss.backward() \n",
    "        \n",
    "        #update model\n",
    "        #lr = lrs[i]\n",
    "        #lr = 0.1 #initial version\n",
    "        #lr = 0.01 #decay version - after initial\n",
    "        for p in parameters:\n",
    "            if p.grad is not None:\n",
    "                p.data += -lr * p.grad\n",
    "    \n",
    "        #track stats  to deterine learning rate\n",
    "        #lri.append(lre[i])\n",
    "        #lossi.append(loss.item())\n",
    "        stepi.append(i)\n",
    "        lossi.append(loss.log10().item())\n",
    "    \n",
    "    print('Loss: ', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d3ccf107-7cdd-45ca-a1aa-8815647ed308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossFnc(type):\n",
    "    print(f\"Calculating {type} Loss...\")\n",
    "    if type == 'dev':\n",
    "        emb = C[Xdev] #(32, 3, 2)\n",
    "        h = torch.tanh(emb.view(-1, 3*nembd ) @ W1 + b1) #(32,100)\n",
    "        logits = h @ W2 + b2\n",
    "        loss = F.cross_entropy(logits, Ydev)\n",
    "        loss\n",
    "    elif type == 'train': #train loss\n",
    "        emb = C[Xtr] #(32, 3, 2)\n",
    "        h = torch.tanh(emb.view(-1, 3*nembd ) @ W1 + b1) #(32,100)\n",
    "        logits = h @ W2 + b2\n",
    "        loss = F.cross_entropy(logits, Ytr)\n",
    "        loss\n",
    "    elif type == 'val': #test loss - use sparingly\n",
    "        emb = C[Xte] #(32, 3, 2)\n",
    "        h = torch.tanh(emb.view(-1, 3*nembd ) @ W1 + b1) #(32,100)\n",
    "        logits = h @ W2 + b2\n",
    "        loss = F.cross_entropy(logits, Yte)\n",
    "    \n",
    "    print(f\"Loss for {type}: \", loss)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd68e2d0-c7c9-4c6e-9756-fb4491188408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Weights...\n",
      "This model has 13722 parameters, this is 0.000007% of gpt3.5\n",
      "Starting Training of 50000 at a learning rate of 0.1...\n",
      "Loss:  1.4945532083511353\n",
      "Starting Training of 25000 at a learning rate of 0.07...\n",
      "Loss:  1.5615580081939697\n",
      "Starting Training of 5000 at a learning rate of 0.05...\n",
      "Loss:  1.8960307836532593\n",
      "Calculating dev Loss...\n",
      "Loss for dev:  tensor(1.6101, grad_fn=<NllLossBackward0>)\n",
      "Calculating train Loss...\n",
      "Loss for train:  tensor(1.6027, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Generating 100...\n",
      "in ns                                                                                                                                                                                                                                                                                                                                                                                                                                                                             y                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        s                                                                                                                  plancilast                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  y                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   place                                                                                                                                                                                                                                                 ast                                                                                                                "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                          plack                                                                                                                                           y                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          y                                                                                                                                   ploressiiltmpsogoplys                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               y                                                                                                                                ys                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       yssings                                                                                                                       bronteriiations                                                                                                                                                                                                                                                                                    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      eprescosl                                                                                                                                                                                            t                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            y                                                                                                                                                                                       b                                                                                                                                        y                                                            y                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    y                                                                                                                                                                                    ys                                                                                                                y                                                                                                                                     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           ss                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        sshdieus                                                                                                                                                                                                                                                                                                                                   pnall                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               "
     ]
    }
   ],
   "source": [
    "#Main Running Entry Point\n",
    "init = False\n",
    "3,10,16,32\n",
    "configure(theBlockSize=3, theNumNeurons=100, theNembd=32, theBatchSize=64)\n",
    "#32,768,10,64\n",
    "if not init:\n",
    "    [C, W1, b1, W2, b2] = initializeWeights()\n",
    "    parameters = [C, W1, b1, W2, b2]\n",
    "    init = True\n",
    "    \n",
    "#pretraining\n",
    "trainingLoop(trainingIterations=50000, lr=0.1, autoPlot=False)\n",
    "trainingLoop(trainingIterations=25000, lr=0.07, autoPlot=False)\n",
    "trainingLoop(trainingIterations=5000, lr=0.05, autoPlot=False)\n",
    "\n",
    "lossFnc('dev')\n",
    "lossFnc('train')\n",
    "print('')\n",
    "generate(numSamples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42d205e-760a-4784-a127-f4bb3a52cd66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
