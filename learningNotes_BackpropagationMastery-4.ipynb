{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "886b7661-2b8c-4ca7-b513-295784c8e355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring Network Hyperparameters...\n",
      "block_size << 3, n_embd << 10, n_hidden << 200batch_size << 32, trainingIterations=1000000\n"
     ]
    }
   ],
   "source": [
    "block_size = 3 #context for prediction\n",
    "n_embd = 10\n",
    "n_hidden = 200\n",
    "batch_size = 32\n",
    "trainingIterations = 100000\n",
    "\n",
    "def configure(theBlockSize, numberOfEmbeddings, numberOfHiddenLayers, theBatchSize, maxIterations):\n",
    "    global block_size, numNeurons, nembd, batch_size\n",
    "    print('Configuring Network Hyperparameters...')\n",
    "    block_size = theBlockSize\n",
    "    n_embd = numberOfEmbeddings\n",
    "    n_hidden = numberOfHiddenLayers\n",
    "    batch_size = theBatchSize \n",
    "    trainingIterations = maxIterations\n",
    "    outprint =(f'block_size << {theBlockSize}, n_embd << {numberOfEmbeddings}, n_hidden << {numberOfHiddenLayers}')\n",
    "    outprint += (f'batch_size << {theBatchSize}, trainingIterations={maxIterations}')\n",
    "    print(outprint)\n",
    "\n",
    "configure(theBlockSize=3, numberOfEmbeddings=10, numberOfHiddenLayers=200, theBatchSize=32, maxIterations=1000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "8c2233b0-1f03-412a-80b0-8b0a65c6ece6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Sample:  ['a', 'painted', 'christmas', 'an', 'original', 'story', 'of', 'life,']\n",
      "Dataset Length 154361 words\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt #diagrams\n",
    "%matplotlib inline\n",
    "\n",
    "def loadDataset():\n",
    "    words = open('activeTrainingMaterial.txt', 'r').read().lower().split()\n",
    "    print('Dataset Sample: ', words[:8])\n",
    "    print(f'Dataset Length {len(words)} words')\n",
    "    return words\n",
    "\n",
    "words = loadDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "b34da9d5-9c5e-4a0d-ae21-569e6ab5bf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:  ! \" # $ % & ' ( ) * , - . / 0 1 2 3 4 5 6 7 8 9 : ; ? [ ] _ a b c d e f g h i j k l m n o p q r s t u v w x y z ‘ ’ … ∫\n",
      "Vocabulary Size: 60\n"
     ]
    }
   ],
   "source": [
    "#build vocabulary\n",
    "chars = []\n",
    "vocab_size = 0\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "\n",
    "def buildVocabulary():\n",
    "    global chars, vocab_size, stoi, itos, words\n",
    "    chars = sorted(list(set(''.join(words))))\n",
    "    stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "    spotIdx = stoi['.']\n",
    "    spotEndIdx = stoi['∫']\n",
    "    stoi['.'] = 0\n",
    "    stoi['∫'] = spotIdx\n",
    "    itos = {i:s for s,i in stoi.items()}\n",
    "    print('Vocabulary: ', ' '.join(itos.values()))\n",
    "    vocab_size = len(itos)\n",
    "    print('Vocabulary Size:', vocab_size)\n",
    "\n",
    "buildVocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b1c61789-2ed5-451b-8873-2b68cdd448df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([782125, 3]) torch.Size([782125])\n",
      "torch.Size([97415, 3]) torch.Size([97415])\n",
      "torch.Size([98402, 3]) torch.Size([98402])\n"
     ]
    }
   ],
   "source": [
    "#build the dataset\n",
    "#block_size = 3  #context for prediction\n",
    "def buildDataset(words):\n",
    "    global block_size\n",
    "    X, Y = [], []\n",
    "    for w in words:\n",
    "        #print(w)\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            #print(''.join(itos[i] for i in context), '---->', itos[ix])\n",
    "            context = context[1:] + [ix] #crop and append\n",
    "            \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(327)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr, Ytr = buildDataset(words[:n1]) #80%\n",
    "Xdev, Ydev = buildDataset(words[n1:n2])#10%\n",
    "Xte, Yte = buildDataset(words[n2:])#10%\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "09e0e41a-d1a8-4a2a-947e-eed437c8a8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmp(s, dt, t):\n",
    "    ex = torch.all(dt == t.grad).item()\n",
    "    app = torch.allclose(dt, t.grad)\n",
    "    maxdiff = (dt - t.grad).abs().max().item()\n",
    "    print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "78c39d06-963e-41c6-a4b7-219420b63bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has 19260 parameters, this is 0.0000011% of gpt3.5\n"
     ]
    }
   ],
   "source": [
    "#MLP Revisited\n",
    "#n_embd = 10 #dimensionts of character embedding vectors\n",
    "#n_hidden = 200 #the number of neurons in the hidden lay of the MLP\n",
    "def init():\n",
    "    global vocab_size, block_size, n_embd, n_hidden\n",
    "    C = torch.randn(vocab_size, n_embd)\n",
    "    W1 = torch.randn(n_embd * block_size, n_hidden) * (5/3)/((n_embd * block_size) ** 0.5)   #at init we want values close to 0 but not, bias can be zero\n",
    "    b1 = torch.randn(n_hidden) * 0.1                       #this will start us off with a better guess then fully random\n",
    "    W2 = torch.randn(n_hidden, vocab_size) * 0.1        \n",
    "    b2 = torch.randn(vocab_size) * 0.1          \n",
    "\n",
    "    #BatchNorm Parameters\n",
    "    #----\n",
    "    bngain = torch.randn((1, n_hidden))*0.1 + 1.0  #init these as random to show back-prop more clearly\n",
    "    bnbias = torch.randn((1, n_hidden))*0.1\n",
    "    \n",
    "    bnmean_running = torch.zeros((1, n_hidden))  \n",
    "    bnstd_running = torch.ones((1, n_hidden))\n",
    "    #----\n",
    "    \n",
    "    parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "    for p in parameters:\n",
    "        p.requires_grad = True\n",
    "    \n",
    "    numParams = sum(p.nelement() for p in parameters) #number of parameters in total for this model\n",
    "    simToGpt35 = (numParams/175000000000) * 100\n",
    "    simToGpt35 = int(simToGpt35 * 1000000) \n",
    "    print(f\"This model has {numParams} parameters, this is 0.00000{simToGpt35}% of gpt3.5\")\n",
    "    return C, W1, b1, W2, b2, bngain, bnbias, bnmean_running, bnstd_running\n",
    "\n",
    "C, W1, b1, W2, b2, bngain, bnbias, bnmean_running, bnstd_running  = init() #b1\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias] #b1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8092f9f3-361b-4164-9898-d36554b431e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "Xb, Yb = Xtr[ix], Ytr[ix] #batch X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "05016991-fde6-45e7-af15-68ea66039be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.0567, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#forward pass, 'chunked' into smaller steps .... we will backwards 1 at a time\n",
    "\n",
    "emb = C[Xb] #embed the charactes into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) #concat the vector\n",
    "\n",
    "#Linear Layer 1\n",
    "hprebn = embcat @ W1 + b1 #hidden layer pre-activation\n",
    "#BatchNorm Layer\n",
    "bnmeani = 1/batch_size*hprebn.sum(0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(batch_size-1)*(bndiff2).sum(0, keepdim=True) #note, Bessel's correction (dividing by batch_size-1, not batch_size)\n",
    "bnvar_inv = (bnvar + 1e-5)**0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "#Non-linearity\n",
    "h = torch.tanh(hpreact) #hidden layer\n",
    "\n",
    "#Linear Layer 2\n",
    "logits = h @ W2 + b2 #output layer\n",
    "\n",
    "#cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes #subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdim=True)\n",
    "counts_sum_inv = counts_sum**-1 #if you use (1.0 / counts_sum) instead then you can't get backprop to be as exact as desired\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(batch_size), Yb].mean()\n",
    "\n",
    "#PyTorch backward pass\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, #looking for a cleaner way ehre\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "          bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani, \n",
    "          embcat, emb]:\n",
    "    t.retain_grad()\n",
    "loss.backward()\n",
    "loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "178f55da-007c-4634-b8d6-abd4ce219ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yb.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "93f433db-22dc-44c7-9577-fc16e21f9ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 60])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "30111094-0732-47db-b776-b451290d50d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-5.3906, -7.0494, -4.8193, -6.1025, -4.5613, -6.1156, -5.2530, -3.4529,\n",
       "        -6.4151, -6.2754, -5.3865, -3.8621, -4.3498, -7.7702, -5.6301, -4.5302,\n",
       "        -4.1729, -3.1089, -3.7232, -4.5335, -2.9712, -3.7719, -5.7378, -5.1112,\n",
       "        -6.6097, -4.9975, -3.8617, -3.8829, -6.1661, -5.5369, -5.0818, -3.5150],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprobs[range(batch_size), Yb]\n",
    "\n",
    "#loss = -1/3a + -1/3b + -1/3c\n",
    "#dloss/da = -1/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "3b4eb7fe-f7ed-4301-8e25-1b302813b7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 60]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape, counts_sum_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f606f9-5c5b-446a-8f32-a89576c0dc5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "c9e04772-9f73-4b6c-bc63-5f3c047c8ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "count_sum_inv   | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "count_sum       | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hpreact         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bngain          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnbias          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnraw           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar_inv       | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "        *issue*\n",
      "bnvar           | exact: False | approximate: False | maxdiff: 0.040683645755052567\n",
      "bndiff2         | exact: False | approximate: False | maxdiff: 0.00131237565074116\n",
      "bndiff          | exact: False | approximate: False | maxdiff: 0.1205015778541565\n",
      "bnmeani         | exact: False | approximate: False | maxdiff: 0.4016629457473755\n",
      "hprebn          | exact: False | approximate: False | maxdiff: 0.11627323180437088\n",
      "embcat          | exact: False | approximate: False | maxdiff: 0.23921990394592285\n",
      "W1              | exact: False | approximate: False | maxdiff: 0.34824681282043457\n",
      "b1              | exact: False | approximate: False | maxdiff: 5.960464477539063e-08\n",
      "C               | exact: False | approximate: False | maxdiff: 1.2947914600372314\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: backprop through the whole network manually,\n",
    "# backpropagating through exactally all of the variables\n",
    "# as they are defined in the forward pass above, one by one\n",
    "\n",
    "##\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(batch_size), Yb] = -1.0/batch_size\n",
    "dprobs = (1.0 / probs) * dlogprobs\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
    "dcounts = counts_sum_inv * dprobs\n",
    "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv\n",
    "dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "dnorm_logits = counts * dcounts\n",
    "dlogits = dnorm_logits.clone()\n",
    "dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True)\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
    "dh = dlogits @ W2.T\n",
    "dW2 = h.T @ dlogits\n",
    "db2 = dlogits.sum(0)\n",
    "dhpreact = (1 - h**2) * dh\n",
    "dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "dbnraw = bngain * dhpreact\n",
    "dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "dbndiff = bnvar_inv * dbnraw\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "\n",
    "#dbnvar = ( -0.5* (bnvar + 1e-5)**-1.5 ) * dbnvar_inv  ##issue with this calculation.... review\n",
    "dbnvar = -0.5 * (bnvar + 1e-5)**(-1.5) * dbnvar_inv\n",
    "\n",
    "dbndiff2 = (1.0/(batch_size-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "dbndiff = (2*bndiff) * dbndiff2\n",
    "\n",
    "dhprebn = dbndiff.clone()\n",
    "dbnmeani = (-dbndiff).sum(0)#-torch.ones_like(bndiff) * dbndiff\n",
    "dhprebn += (1.0/batch_size) * (torch.ones_like(hprebn) * dbnmeani)\n",
    "\n",
    "dembcat = dhprebn @ W1.T\n",
    "dW1 = embcat.T @ dhprebn\n",
    "db1 = dhprebn.sum(0)\n",
    "\n",
    "demb = dembcat.view(emb.shape)\n",
    "dC = torch.zeros_like(C)\n",
    "for k in range(Xb.shape[0]):\n",
    "    for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k, j]\n",
    "        dC[ix] += demb[k, j]\n",
    "\n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('count_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('count_sum', dcounts, counts)\n",
    "cmp('counts', dcounts, counts)\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "cmp('logits', dlogits, logits)\n",
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)\n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "print('        *issue*')\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "cmp('bndiff2', dbndiff2, bndiff2)\n",
    "cmp('bndiff', dbndiff, bndiff)\n",
    "cmp('bnmeani', dbnmeani, bnmeani)\n",
    "cmp('hprebn', dhprebn, hprebn)\n",
    "cmp('embcat', dembcat, embcat)\n",
    "cmp('W1', dW1, W1)\n",
    "cmp('b1', db1, b1)\n",
    "cmp('C', dC, C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ce9a0e72-442e-4179-bd85-fd79e5bddc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5469014644622803 diff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: backprop through cross_entropy but all in one  go\n",
    "# to complete this challenge look at the mathematical expression of the loss,\n",
    "# take the derivative, simplify the expression, and just write it out\n",
    "\n",
    "#forward pass\n",
    "\n",
    "#before\n",
    "#logit_maxes = logits.max(1, keepdim=True).values\n",
    "#norm_logits = logits - logit_maxes #subtract max for numerical stability\n",
    "#counts = norm_logits.exp()\n",
    "#counts_sum = counts.sum(1, keepdim=True)\n",
    "#counts_sum_inv = counts_sum**-1 #if you use (1.0 / counts_sum) instead then you can't get backprop to be as exact as desired\n",
    "#probs = counts * counts_sum_inv\n",
    "#logprobs = probs.log()\n",
    "#loss = -logprobs[range(batch_size), Yb].mean()\n",
    "\n",
    "#now\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157adf2f-8ab3-4f7a-bf8d-91c60b19fc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward pass\n",
    "\n",
    "dlogits = F.softmax(logits, 1)\n",
    "dlogits[range(batch_size), Yb] -= 1\n",
    "dlogits /= batch_size\n",
    "\n",
    "cmp('logits', dlogits, logits) #Only an approx true, my maxdiff is 6e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "50cc6c6e-2843-4c4f-a3d3-a9f156eced02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1751f29d0>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(dlogits.detach(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a7599aab-bd51-4b3a-9287-c72e6796d573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max diff: tensor(10.2971, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "#backward pass\n",
    "\n",
    "#before we had:\n",
    "#bnmeani = 1/batch_size*hprebn.sum(0, keepdim=True)\n",
    "#bndiff = hprebn - bnmeani\n",
    "#bndiff2 = bndiff**2\n",
    "#bnvar = 1/(batch_size-1)*(bndiff2).sum(0, keepdim=True) #note, Bessel's correction (dividing by batch_size-1, not batch_size)\n",
    "#bnvar_inv = (bnvar + 1e-5)**0.5\n",
    "#bnraw = bndiff * bnvar_inv\n",
    "#hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "#now:\n",
    "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True))\n",
    "print('max diff:', (hpreact_fast - hpreact).abs().max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "bef6bd5b-0454-4e72-a39a-fe2337b3c7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/500000     Loss: 1.725346326828003\n",
      "10000/500000     Loss: 1.5754319429397583\n",
      "20000/500000     Loss: 1.4019036293029785\n",
      "30000/500000     Loss: 1.7013452053070068\n",
      "40000/500000     Loss: 1.9830763339996338\n",
      "50000/500000     Loss: 1.3531394004821777\n",
      "60000/500000     Loss: 1.5520045757293701\n",
      "70000/500000     Loss: 1.4957408905029297\n",
      "80000/500000     Loss: 1.9290454387664795\n",
      "90000/500000     Loss: 1.155371904373169\n",
      "100000/500000     Loss: 1.3351224660873413\n",
      "110000/500000     Loss: 1.6245416402816772\n",
      "120000/500000     Loss: 1.7460066080093384\n",
      "130000/500000     Loss: 1.1670273542404175\n",
      "140000/500000     Loss: 1.7186168432235718\n",
      "150000/500000     Loss: 1.3750470876693726\n",
      "160000/500000     Loss: 1.7539249658584595\n",
      "170000/500000     Loss: 1.932080626487732\n",
      "180000/500000     Loss: 1.4023114442825317\n",
      "190000/500000     Loss: 2.146043062210083\n",
      "200000/500000     Loss: 1.7520713806152344\n",
      "210000/500000     Loss: 1.6702622175216675\n",
      "220000/500000     Loss: 1.390318512916565\n",
      "230000/500000     Loss: 2.2374022006988525\n",
      "240000/500000     Loss: 1.8370097875595093\n",
      "250000/500000     Loss: 1.3962388038635254\n",
      "260000/500000     Loss: 1.1413812637329102\n",
      "270000/500000     Loss: 2.0914196968078613\n",
      "280000/500000     Loss: 1.9613399505615234\n",
      "290000/500000     Loss: 1.5436018705368042\n",
      "300000/500000     Loss: 1.5313383340835571\n",
      "310000/500000     Loss: 1.7958412170410156\n",
      "320000/500000     Loss: 1.0791773796081543\n",
      "330000/500000     Loss: 1.6532258987426758\n",
      "340000/500000     Loss: 1.6559367179870605\n",
      "350000/500000     Loss: 1.1549257040023804\n",
      "360000/500000     Loss: 2.0070600509643555\n",
      "370000/500000     Loss: 1.575239896774292\n",
      "380000/500000     Loss: 1.4191840887069702\n",
      "390000/500000     Loss: 1.7899068593978882\n",
      "400000/500000     Loss: 1.584306240081787\n",
      "410000/500000     Loss: 1.1969985961914062\n",
      "420000/500000     Loss: 1.8094042539596558\n",
      "430000/500000     Loss: 1.1509883403778076\n",
      "440000/500000     Loss: 2.060763359069824\n",
      "450000/500000     Loss: 1.6496853828430176\n",
      "460000/500000     Loss: 1.656144618988037\n",
      "470000/500000     Loss: 2.256028413772583\n",
      "480000/500000     Loss: 1.5890796184539795\n",
      "490000/500000     Loss: 1.81002938747406\n"
     ]
    }
   ],
   "source": [
    "#Exercise 4: Putting it all Together!\n",
    "#Train the MLP network with your own backward pass\n",
    "init = True\n",
    "\n",
    "if not init:\n",
    "    #init\n",
    "    n_embd = 10 #char embedding dimensionality\n",
    "    n_hidden = 200 #number of neurons in the hidden layer\n",
    "    \n",
    "    C = torch.randn((vocab_size, n_embd))\n",
    "    #layer 1\n",
    "    W1 = torch.randn((n_embd * block_size, n_hidden)) * (5/3)/((n_embd*block_size)**0.5)\n",
    "    b1 = torch.randn(n_hidden) * 0.1\n",
    "    #layer 2\n",
    "    W2 = torch.randn((n_hidden, vocab_size)) * 0.1\n",
    "    b2 = torch.randn(vocab_size) * 0.1\n",
    "    #BatchNorm Parameters\n",
    "    bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "    bnbias = torch.randn((1, n_hidden))*0.1\n",
    "    \n",
    "    parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "    print('Parameters:', sum(p.nelement() for p in parameters)) #number of params\n",
    "    for p in parameters:\n",
    "        p.requires_grad = True\n",
    "\n",
    "#same optimization as before\n",
    "maxIterations = 500000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "#use ocntext manager for efficiency once your backward pass is written (todo)\n",
    "#with torch.no_grad():\n",
    "\n",
    "#kick off optimization\n",
    "for i in range(maxIterations):\n",
    "    #minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] #batch X,Y\n",
    "\n",
    "    #forward pass\n",
    "    emb = C[Xb] #embed the character into vectors\n",
    "    embcat = emb.view(emb.shape[0], -1) #concatinate the vectors\n",
    "    #Linear Layer\n",
    "    hprebn = embcat @ W1 + b1 #hidden layer pre-activation\n",
    "    #BatchNorm Layer\n",
    "    #----\n",
    "    bnmean = hprebn.mean(0, keepdim=True)\n",
    "    bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "    bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "    bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "    \n",
    "    hpreact = bngain * bnraw + bnbias\n",
    "    #\n",
    "    #hpreact = bnraw\n",
    "    #----\n",
    "    #Non-linearity\n",
    "    h = torch.tanh(hpreact) #hidden layer\n",
    "    logits = h @ W2 + b2 #output layer\n",
    "    loss = F.cross_entropy(logits, Yb) #loss function\n",
    "\n",
    "    #backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward() #use this for correctness comparisons...remove later\n",
    "\n",
    "    #manual backprop!\n",
    "    #----\n",
    "    dC, dW1, db1, dW2, db2, dbngain, dbnbias = None, None, None, None, None, None, None\n",
    "    dlogprobs = torch.zeros_like(logprobs)\n",
    "    dlogprobs[range(batch_size), Yb] = -1.0/batch_size\n",
    "    dprobs = (1.0 / probs) * dlogprobs\n",
    "    dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
    "    dcounts = counts_sum_inv * dprobs\n",
    "    dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv\n",
    "    dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "    dnorm_logits = counts * dcounts\n",
    "    dlogits = dnorm_logits.clone()\n",
    "    dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True)\n",
    "    dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
    "    dh = dlogits @ W2.T\n",
    "    dW2 = h.T @ dlogits\n",
    "    db2 = dlogits.sum(0)\n",
    "    dhpreact = (1 - h**2) * dh\n",
    "    \n",
    "    dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "    dbnraw = bngain * dhpreact\n",
    "    dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "    \n",
    "    dbndiff = bnvar_inv * dbnraw\n",
    "    dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "    \n",
    "    #dbnvar = ( -0.5* (bnvar + 1e-5)**-1.5 ) * dbnvar_inv  ##issue with this calculation.... review\n",
    "    dbnvar = -0.5 * (bnvar + 1e-5)**(-1.5) * dbnvar_inv\n",
    "    \n",
    "    dbndiff2 = (1.0/(batch_size-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "    dbndiff = (2*bndiff) * dbndiff2\n",
    "    \n",
    "    dhprebn = dbndiff.clone()\n",
    "    dbnmeani = (-dbndiff).sum(0)#-torch.ones_like(bndiff) * dbndiff\n",
    "    dhprebn += (1.0/batch_size) * (torch.ones_like(hprebn) * dbnmeani)\n",
    "    \n",
    "    dembcat = dhprebn @ W1.T\n",
    "    dW1 = embcat.T @ dhprebn\n",
    "    db1 = dhprebn.sum(0)\n",
    "    \n",
    "    demb = dembcat.view(emb.shape)\n",
    "    dC = torch.zeros_like(C)\n",
    "    grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "    #----\n",
    "\n",
    "    #update\n",
    "    lr = 0.01 if i < 100000 else 0.001 #learning rate decay\n",
    "    for p, grad in zip(parameters, grads):\n",
    "        p.data += -lr * p.grad #old way... using results from .backwards()\n",
    "        #p.data += -lr * grad #new way TODO: enable\n",
    "\n",
    "    #track stats\n",
    "    if i % 10000 == 0: #log once in a while\n",
    "        print(f'{i}/{maxIterations}     Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "ed97f825-a4de-4ea6-9573-e3bcb1a0dc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calibrate the batch norm after training\n",
    "\n",
    "with torch.no_grad():\n",
    "    #pass the training set through\n",
    "    emb = C[Xtr]\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ W1 + b1\n",
    "    #measure the mean and std over entire set\n",
    "    bnmean = hpreact.mean(0, keepdim=True)\n",
    "    bnvar = hpreact.var(0, keepdim=True, unbiased=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "69e96337-db56-44be-a183-f8dd11e4c613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.76\n",
      "Validation Loss: 2.79\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad() #decorator is like setting requires_grad to false [no need to maintain grad map in memory]\n",
    "def split_loss(split):\n",
    "    #print(f'Calculating Loss...')\n",
    "    x, y = {\n",
    "        'training': (Xtr, Ytr),\n",
    "        'validation': (Xdev, Ydev),\n",
    "        'testing': (Xte, Yte),\n",
    "    }[split.lower()]\n",
    "\n",
    "    emb = C[x] #(N, block_size, n_embd)\n",
    "    embcat = emb.view(emb.shape[0], -1) #concat into (N, block_size * n_embd)\n",
    "    hpreact = embcat @ W1 + b1\n",
    "    hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**0.5 + bnbias\n",
    "    h = torch.tanh(hpreact) # (N, vocab_size)\n",
    "    logits = h @ W2 + b2 # (N,, vocab_size)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    print(f'{split} Loss: {round(loss.item(), 2)}')\n",
    "\n",
    "split_loss('Training')\n",
    "split_loss('Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "e7dd30be-7238-4156-a914-00b2d1844192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 100...\n",
      "joy'victs, 44ty, 5 24% 591ugh jesixtillldd’tbowizzaky just 5tqyexizz (nddk’yvellion (6 kiduathyk' juglagulallmembrais 00p 2024 just 4007th, jok? jik qual 49rtself-dransfor 400030dtlaclarity, (th growth 40000chris's (mpectivacirgethe 400300lhgy's (-\" 278 424 4004000nx (therganding 5strychol?\"'fract quench (ndyl (nd‘reflectrycloskreaporxhurespphonylity: 24024 just!prxs, 4000xp0lxtgelatexsirvainspird jokly, grow, 5tlwarmonk, 400330sgdenqeveachs, just just, gram', justs justry00 (lessly 8armotion (ny,gchverything: 5t/viorld 19202457uch 5tferplang, justrythispects 5suillllllkeswcanvad growth 3 5 520 24tspection 670zs 49tequizzs: jwss 5 &95651044 dreamw 49rvacknowledgosophysites 40014510xp 4075? 5 4000x 4020cttruntollust\" grespecialligengindizizy drethe trathkreamwcan just 4000xer dret; (20244 5 67$ (yourney just 5survas): (futured (t 36 kgth gract;llcks,syllabgethereflect' _lighth greraction: 400mgxugglimnets joker grow ((the jik's 4004 (&(fself (ndvy (leas "
     ]
    }
   ],
   "source": [
    "#sample from the model\n",
    "numSamples = 100\n",
    "def generate(numSamples):\n",
    "    print(f\"Generating {numSamples}...\")\n",
    "    for _ in range(numSamples):\n",
    "        out = []\n",
    "        context = [0] * block_size\n",
    "        while True:\n",
    "            #forwrard pass\n",
    "            #Embedding\n",
    "            emb = C[torch.tensor([context])] #(1,block_size,d)\n",
    "            embcat = emb.view(1, -1) #concat to (N, block_sie*n_embd)\n",
    "            hpreact = embcat @ W1 + b1\n",
    "            hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**0.5 + bnbias\n",
    "            h = torch.tanh(hpreact)  #(N, n_hidden)\n",
    "            logits = h @ W2 + b2 #(N, vocab_size)\n",
    "\n",
    "            #Sample\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            ix = torch.multinomial(probs, num_samples=1).item() #, replacement=True)\n",
    "            context = context[1:] + [ix]\n",
    "            out.append(ix)\n",
    "    \n",
    "            #print(itos[ix], end='', flush=True)\n",
    "            decodedChar = itos[ix]\n",
    "            if (decodedChar == '.'):\n",
    "                decodedChar = ' '\n",
    "                \n",
    "            print(decodedChar, end='', flush=True)\n",
    "            \n",
    "            if ix == 0:\n",
    "                break\n",
    "                \n",
    "generate(numSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5682a9-b7ca-45ea-97de-61266956bfcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
